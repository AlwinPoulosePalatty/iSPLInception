This is the report for the daphnet Dataset

Data Distribution: 

Train:  X -> (7945, 192, 9) Class count -> [7251, 694] 

           frequency
No freeze  91.264946
Freeze      8.735053

Validation:  X -> (1602, 192, 9) Class count -> [1345, 257] 

           frequency
No freeze  83.957550
Freeze     16.042446

Test:  X -> (2332, 192, 9) Class count -> [2165, 167] 

           frequency
No freeze  92.838760
Freeze      7.161235

iSPLInception Model : 2021-02-06 18:07:04.913580
Model History 
         loss  accuracy  val_loss  val_accuracy        lr
0    5.405303  0.920076  3.555784      0.839576  0.000500
1    2.283280  0.937697  2.077174      0.839576  0.000500
2    1.407540  0.937445  1.448155      0.841448  0.000500
3    0.979520  0.941347  1.110232      0.839576  0.000500
4    0.713411  0.946256  0.896626      0.839576  0.000500
5    0.548485  0.945249  1.023313      0.839576  0.000500
6    0.426069  0.948773  0.696402      0.840200  0.000500
7    0.364931  0.944368  0.555552      0.842697  0.000500
8    0.300328  0.948773  0.556545      0.840824  0.000500
9    0.254865  0.951416  0.509501      0.842072  0.000500
10   0.230164  0.952801  0.597421      0.847690  0.000500
11   0.220791  0.949276  0.417737      0.848315  0.000500
12   0.205693  0.953430  0.442020      0.841448  0.000500
13   0.193540  0.953807  0.391900      0.880150  0.000500
14   0.190054  0.958213  0.538354      0.840200  0.000500
15   0.177615  0.957835  0.580732      0.842072  0.000500
16   0.176294  0.957332  0.667022      0.840200  0.000500
17   0.175491  0.958464  0.418602      0.845194  0.000500
18   0.161090  0.957961  0.390880      0.867041  0.000500
19   0.153790  0.959597  0.451424      0.846442  0.000500
20   0.149867  0.959975  0.446175      0.850187  0.000500
21   0.166406  0.961863  0.419542      0.850811  0.000500
22   0.153276  0.961863  0.473682      0.851436  0.000500
23   0.148880  0.963877  0.442153      0.839576  0.000500
24   0.151525  0.960856  0.609914      0.850187  0.000500
25   0.192596  0.964506  0.535210      0.849563  0.000500
26   0.160564  0.963373  0.930778      0.838951  0.000500
27   0.140216  0.966268  0.474663      0.850187  0.000500
28   0.140255  0.967904  0.480965      0.850811  0.000500
29   0.132509  0.966646  0.860589      0.842072  0.000500
30   0.131528  0.969541  0.759246      0.839576  0.000500
31   0.127595  0.968282  0.465758      0.860799  0.000500
32   0.129229  0.970044  0.683270      0.847066  0.000500
33   0.129989  0.968534  0.457601      0.870162  0.000500
34   0.126396  0.968785  0.488474      0.846442  0.000500
35   0.120511  0.969163  0.488315      0.850811  0.000500
36   0.129041  0.968534  0.590015      0.848315  0.000500
37   0.119838  0.970422  0.991009      0.840200  0.000500
38   0.122539  0.970547  0.436769      0.829588  0.000500
39   0.116576  0.974072  0.594155      0.853933  0.000500
40   0.114449  0.971051  1.237270      0.840200  0.000500
41   0.112564  0.973820  0.492388      0.852060  0.000500
42   0.120536  0.970170  0.485376      0.859551  0.000500
43   0.111215  0.974575  1.054259      0.839576  0.000500
44   0.104712  0.975456  0.782548      0.847066  0.000500
45   0.118259  0.971177  1.034148      0.840824  0.000500
46   0.103908  0.975079  0.713322      0.839576  0.000500
47   0.107778  0.975582  0.411898      0.855805  0.000500
48   0.108556  0.974323  0.644452      0.865169  0.000500
49   0.107480  0.976211  0.759156      0.845818  0.000500
50   0.105317  0.976589  0.538490      0.847690  0.000500
51   0.126362  0.973694  0.843696      0.844569  0.000500
52   0.118708  0.973946  0.579491      0.844569  0.000500
53   0.115357  0.972939  0.862566      0.841448  0.000500
54   0.107325  0.976086  0.453374      0.853933  0.000500
55   0.106835  0.977093  0.442419      0.867665  0.000500
56   0.105524  0.977470  1.032503      0.843321  0.000500
57   0.096946  0.978980  0.485899      0.836454  0.000400
58   0.094156  0.980868  0.628467      0.848315  0.000400
59   0.099023  0.979610  0.920511      0.840200  0.000400
60   0.090836  0.981498  0.694911      0.848315  0.000400
61   0.094695  0.979987  0.683895      0.830212  0.000400
62   0.090631  0.981498  0.625950      0.851436  0.000400
63   0.118117  0.976086  1.027181      0.842697  0.000400
64   0.097444  0.980617  0.908348      0.842072  0.000400
65   0.095328  0.981875  0.784921      0.846442  0.000400
66   0.090605  0.982253  0.645855      0.843945  0.000400
67   0.123679  0.972435  0.589656      0.852060  0.000400
68   0.099233  0.980113  1.184944      0.842697  0.000400
69   0.112309  0.981120  0.760453      0.848315  0.000400
70   0.102861  0.979358  0.744703      0.845194  0.000400
71   0.094217  0.981120  1.001005      0.843945  0.000400
72   0.092618  0.981875  0.763789      0.844569  0.000400
73   0.091141  0.984015  0.615188      0.849563  0.000320
74   0.077953  0.987036  0.658857      0.846442  0.000320
75   0.092198  0.982001  0.715718      0.847066  0.000320
76   0.074936  0.988924  0.840255      0.846442  0.000320
77   0.076289  0.986658  1.005950      0.846442  0.000320
78   0.077112  0.985903  0.655565      0.848939  0.000320
79   0.074477  0.987665  0.968078      0.843945  0.000320
80   0.071790  0.987665  1.092691      0.848939  0.000320
81   0.074166  0.987413  0.958651      0.848939  0.000320
82   0.071518  0.988169  0.910598      0.847690  0.000320
83   0.080835  0.983889  0.948207      0.847690  0.000320
84   0.083230  0.984644  0.686676      0.855181  0.000320
85   0.080448  0.987288  0.515602      0.850811  0.000320
86   0.070465  0.989553  0.906045      0.848315  0.000320
87   0.069842  0.987539  1.225901      0.852684  0.000320
88   0.081645  0.984519  1.196681      0.844569  0.000320
89   0.090233  0.983512  0.613233      0.862047  0.000320
90   0.083833  0.986407  0.913404      0.851436  0.000320
91   0.080802  0.985274  0.771612      0.848939  0.000320
92   0.072102  0.988420  0.945574      0.847066  0.000320
93   0.073146  0.987917  0.614684      0.861423  0.000320
94   0.074151  0.986407  0.992281      0.847690  0.000320
95   0.072115  0.988924  0.630445      0.856429  0.000320
96   0.070666  0.988043  0.663413      0.851436  0.000320
97   0.073125  0.988043  0.837043      0.841448  0.000320
98   0.068854  0.990057  0.777201      0.852060  0.000256
99   0.065581  0.989679  0.885932      0.857054  0.000256
100  0.063620  0.990434  0.797025      0.853933  0.000256
101  0.060767  0.991315  0.766258      0.850187  0.000256
102  0.064278  0.988798  0.898392      0.854557  0.000256
103  0.058615  0.991189  0.955834      0.851436  0.000256
104  0.057417  0.991945  0.947919      0.846442  0.000256
105  0.059499  0.989553  0.687056      0.857678  0.000256
106  0.080488  0.986532  1.107681      0.841448  0.000256
107  0.077269  0.986658  0.519124      0.864544  0.000256
108  0.073092  0.988420  0.757855      0.862047  0.000256
109  0.075125  0.986155  1.372646      0.844569  0.000256
110  0.065212  0.990183  0.819834      0.851436  0.000256
111  0.060018  0.991567  0.939076      0.845818  0.000256
112  0.063273  0.989931  1.348486      0.848939  0.000256
113  0.060222  0.990812  0.632603      0.862047  0.000256
114  0.060450  0.989050  0.721994      0.865793  0.000256
115  0.056971  0.991819  0.637593      0.867665  0.000205
116  0.052410  0.993958  0.980723      0.850187  0.000205
117  0.054874  0.991819  1.196575      0.848939  0.000205
118  0.057486  0.992196  0.828306      0.847066  0.000205
119  0.057633  0.990560  1.780841      0.844569  0.000205
120  0.057327  0.992196  1.087654      0.852060  0.000205
121  0.053530  0.992700  0.792324      0.848315  0.000205
122  0.059275  0.990057  0.758514      0.858302  0.000205
123  0.052579  0.992070  0.720704      0.852060  0.000205
124  0.056170  0.991189  0.657069      0.860799  0.000205
125  0.048365  0.994336  0.905144      0.856429  0.000205
126  0.049504  0.993581  0.567154      0.865169  0.000205
127  0.064370  0.990686  1.033526      0.847690  0.000205
128  0.054749  0.993581  0.995678      0.850187  0.000205
129  0.061710  0.989679  0.767985      0.855805  0.000205
130  0.057970  0.990938  0.652187      0.863296  0.000205
131  0.054747  0.992322  1.076161      0.853308  0.000205
132  0.052253  0.992952  0.916006      0.852060  0.000205
133  0.061116  0.989553  1.429014      0.845818  0.000205
134  0.065464  0.988295  0.491936      0.862047  0.000205
135  0.055341  0.992448  0.781796      0.850187  0.000205
136  0.056547  0.991693  0.606934      0.858926  0.000164
137  0.051430  0.994588  0.790525      0.849563  0.000164
138  0.050081  0.994210  0.612386      0.860799  0.000164
139  0.051088  0.992700  0.684929      0.853308  0.000164
140  0.055210  0.992322  0.817487      0.852060  0.000164
141  0.049409  0.993203  0.631236      0.865169  0.000164
142  0.049058  0.993833  0.576281      0.863296  0.000164
143  0.047378  0.994714  0.859242      0.854557  0.000164
144  0.050112  0.992826  0.889228      0.850187  0.000164
145  0.046201  0.994462  0.866701      0.855181  0.000164
146  0.046877  0.994336  0.949109      0.850187  0.000164
147  0.044623  0.994840  0.888488      0.851436  0.000164
148  0.046828  0.994336  1.095014      0.850187  0.000164
149  0.064554  0.986910  0.904670      0.855805  0.000164
150  0.051330  0.992322  0.739379      0.861423  0.000164
151  0.048045  0.993958  0.517074      0.867665  0.000164
152  0.046005  0.995091  0.653366      0.860799  0.000164
153  0.045159  0.994084  1.508973      0.844569  0.000164
154  0.045633  0.993833  0.928258      0.844569  0.000164
155  0.045037  0.993707  1.042342      0.855181  0.000164
156  0.045038  0.994462  0.934636      0.852060  0.000164
157  0.043350  0.995091  1.065015      0.848315  0.000164
158  0.045337  0.994840  0.888330      0.852684  0.000164
159  0.045580  0.993077  0.974737      0.848315  0.000164
160  0.048419  0.993077  0.728223      0.857054  0.000164
161  0.048715  0.992952  0.739618      0.862047  0.000164
162  0.044499  0.994840  0.875172      0.859551  0.000164
163  0.043501  0.994714  0.789579      0.859551  0.000164
164  0.044916  0.993958  1.020391      0.855805  0.000164
165  0.046688  0.994336  0.615223      0.856429  0.000164
166  0.045369  0.994714  0.982889      0.851436  0.000164
167  0.045966  0.994462  0.723962      0.865169  0.000164
168  0.041248  0.995846  0.945282      0.849563  0.000131
169  0.041396  0.995343  0.817107      0.858926  0.000131
170  0.039636  0.995595  0.890010      0.858926  0.000131
171  0.041641  0.995469  0.763036      0.861423  0.000131
172  0.054536  0.990183  0.833161      0.856429  0.000131
173  0.048421  0.993958  0.598325      0.861423  0.000131
174  0.044700  0.994840  0.549153      0.868290  0.000131
175  0.041535  0.995091  0.892932      0.855181  0.000131
176  0.040561  0.996224  0.863672      0.859551  0.000131
177  0.042687  0.995343  1.029314      0.854557  0.000131
178  0.038634  0.996224  0.868374      0.855805  0.000131
179  0.039773  0.996476  0.895578      0.855181  0.000131
180  0.038008  0.996098  0.782105      0.861423  0.000131
181  0.039954  0.995595  0.898582      0.859551  0.000131
182  0.040249  0.995217  0.670177      0.865169  0.000131
183  0.037926  0.996350  0.766537      0.862672  0.000131
184  0.046391  0.993329  0.684906      0.865169  0.000131
185  0.043779  0.994336  0.745836      0.862047  0.000131
186  0.039169  0.996224  0.683747      0.857678  0.000131
187  0.040810  0.994714  0.839450      0.860799  0.000131
188  0.040975  0.994462  0.907701      0.861423  0.000131
189  0.038907  0.995972  0.772637      0.863920  0.000131
190  0.038948  0.995721  0.889767      0.857054  0.000131
191  0.039671  0.996224  0.781764      0.859551  0.000105
192  0.035334  0.997105  0.774035      0.860799  0.000105
193  0.038059  0.996350  0.954192      0.854557  0.000105
194  0.037256  0.995721  0.934703      0.855805  0.000105
195  0.035510  0.997357  0.890193      0.853933  0.000105
196  0.034813  0.996979  1.137088      0.849563  0.000105
197  0.036421  0.995846  0.786933      0.860175  0.000105
198  0.035588  0.996728  0.695424      0.856429  0.000105
199  0.037810  0.995343  0.874782      0.860799  0.000105
200  0.037338  0.995469  0.919637      0.857678  0.000105
201  0.035311  0.996224  1.086242      0.857054  0.000105
202  0.035548  0.996350  0.907670      0.855805  0.000105
203  0.035395  0.996350  1.105670      0.850811  0.000105
204  0.034261  0.996853  0.852447      0.857678  0.000105
205  0.038913  0.995469  0.910726      0.860799  0.000105
206  0.035255  0.996350  0.965706      0.858926  0.000105
207  0.034932  0.996602  0.957825      0.863920  0.000105
208  0.032341  0.997231  1.051461      0.858926  0.000105
209  0.034605  0.996979  0.782224      0.860799  0.000105
210  0.033698  0.996853  0.864392      0.855181  0.000105
211  0.034862  0.995846  0.882032      0.861423  0.000105
212  0.033882  0.996728  0.726863      0.858302  0.000105
213  0.052002  0.989805  0.950863      0.853308  0.000105
214  0.036457  0.995469  0.756074      0.860799  0.000105
215  0.037699  0.995469  0.734726      0.863296  0.000105
216  0.045098  0.993707  0.913616      0.854557  0.000105
217  0.037355  0.995972  0.586540      0.864544  0.000105
218  0.037134  0.995469  0.950515      0.852684  0.000105
219  0.036118  0.996224  0.695403      0.867665  0.000100
220  0.036989  0.995972  0.624893      0.867665  0.000100
221  0.037957  0.995972  0.739915      0.866417  0.000100
222  0.040296  0.994588  0.801968      0.863920  0.000100
223  0.036319  0.995721  0.909957      0.864544  0.000100
224  0.033903  0.996853  0.768549      0.870162  0.000100
225  0.040114  0.995846  1.083229      0.849563  0.000100
226  0.034670  0.996728  0.705207      0.852684  0.000100
227  0.043393  0.994588  0.946018      0.853933  0.000100
228  0.038425  0.995846  0.952493      0.858302  0.000100
229  0.034097  0.996728  0.839436      0.859551  0.000100
230  0.034260  0.996979  1.058324      0.860175  0.000100
231  0.034665  0.996476  1.174761      0.852684  0.000100
232  0.034182  0.996602  1.136462      0.856429  0.000100
233  0.034805  0.996098  0.833186      0.869538  0.000100
234  0.033207  0.996728  0.984712      0.860175  0.000100
235  0.031935  0.997609  0.973268      0.860799  0.000100
236  0.034179  0.996602  0.975289      0.859551  0.000100
237  0.029509  0.998490  0.985465      0.859551  0.000100
238  0.031172  0.996728  1.080418      0.855181  0.000100
239  0.031793  0.997734  0.977642      0.857054  0.000100
240  0.033179  0.996602  0.875460      0.861423  0.000100
241  0.030759  0.997734  0.996543      0.862672  0.000100
242  0.035763  0.996098  0.916855      0.858302  0.000100
243  0.031597  0.997734  0.832061      0.860799  0.000100
244  0.030491  0.997357  0.894021      0.863920  0.000100
245  0.030263  0.997357  0.918046      0.860175  0.000100
246  0.033401  0.996350  0.892339      0.857054  0.000100
247  0.039885  0.993958  0.797885      0.870786  0.000100
248  0.033309  0.997105  0.886373      0.863920  0.000100
249  0.033229  0.996602  0.844284      0.860175  0.000100
250  0.031366  0.997357  0.810163      0.865793  0.000100
251  0.029772  0.997231  0.875267      0.863920  0.000100
252  0.031923  0.996728  0.733692      0.873283  0.000100
253  0.028322  0.998490  0.904719      0.858926  0.000100
254  0.028704  0.997483  1.065625      0.858302  0.000100
255  0.032532  0.995972  0.651559      0.871411  0.000100
256  0.035262  0.995846  0.836977      0.858302  0.000100
257  0.029441  0.997860  0.864096      0.857054  0.000100
258  0.029334  0.997609  0.903555      0.854557  0.000100
259  0.029782  0.997231  0.952931      0.854557  0.000100
260  0.028294  0.997734  0.941850      0.860175  0.000100
261  0.030810  0.996728  0.965704      0.859551  0.000100
262  0.033254  0.996350  0.886577      0.860175  0.000100
263  0.031784  0.996979  0.696666      0.861423  0.000100
264  0.029342  0.997860  0.807005      0.865793  0.000100
265  0.032456  0.997231  0.829980      0.862047  0.000100
266  0.036598  0.995217  0.842210      0.850811  0.000100
267  0.032110  0.996476  0.657820      0.875156  0.000100
268  0.029831  0.998364  0.700541      0.873283  0.000100
269  0.033065  0.996224  0.697419      0.870162  0.000100
270  0.028996  0.997609  0.693617      0.870786  0.000100
271  0.027792  0.998112  0.828658      0.859551  0.000100
272  0.032041  0.996224  0.760992      0.865169  0.000100
273  0.029391  0.997483  0.703656      0.867665  0.000100
274  0.028626  0.997734  0.881663      0.863296  0.000100
275  0.027964  0.997609  0.521105      0.877029  0.000100
276  0.030240  0.997105  0.755437      0.866417  0.000100
277  0.029502  0.997860  0.694506      0.868290  0.000100
278  0.028578  0.997105  1.239450      0.848315  0.000100
279  0.028216  0.997860  0.681473      0.869538  0.000100
280  0.029402  0.997231  0.866651      0.856429  0.000100
281  0.029016  0.997231  0.810624      0.862047  0.000100
282  0.027350  0.997734  0.672105      0.868914  0.000100
283  0.028068  0.996853  0.699902      0.867041  0.000100
284  0.028767  0.996979  1.152202      0.851436  0.000100
285  0.029276  0.996602  1.000884      0.852060  0.000100
286  0.026366  0.998112  0.673513      0.866417  0.000100
287  0.029592  0.996602  1.298693      0.848315  0.000100
288  0.027850  0.997357  0.954673      0.850811  0.000100
289  0.029542  0.996979  0.832487      0.860799  0.000100
290  0.025490  0.998490  0.736073      0.868914  0.000100
291  0.028967  0.996602  0.999367      0.861423  0.000100
292  0.028352  0.997483  0.978463      0.858302  0.000100
293  0.028270  0.997609  1.122027      0.850187  0.000100
294  0.029838  0.996350  0.879853      0.850187  0.000100
295  0.029011  0.996098  0.892112      0.857054  0.000100
296  0.031980  0.995972  0.760902      0.870786  0.000100
297  0.028629  0.998112  0.941676      0.857054  0.000100
298  0.030800  0.996728  0.766365      0.865169  0.000100
299  0.027262  0.997734  0.924146      0.851436  0.000100
300  0.031622  0.996350  0.736706      0.863920  0.000100
301  0.028711  0.997105  0.930594      0.855805  0.000100
302  0.028016  0.997483  1.078616      0.850811  0.000100
303  0.035353  0.994965  0.929579      0.860175  0.000100
304  0.030592  0.997105  0.812929      0.863296  0.000100
305  0.031778  0.995846  1.027324      0.861423  0.000100
306  0.039773  0.993958  0.973382      0.860175  0.000100
307  0.030322  0.998112  0.806152      0.862047  0.000100
308  0.030784  0.996728  0.568632      0.871411  0.000100
309  0.030164  0.996979  0.744976      0.870162  0.000100
310  0.028163  0.997483  0.795759      0.865169  0.000100
311  0.026958  0.997734  0.874742      0.866417  0.000100
312  0.032046  0.995595  0.916142      0.862672  0.000100
313  0.030547  0.997357  0.898590      0.860175  0.000100
314  0.028789  0.996979  0.887364      0.856429  0.000100
315  0.029139  0.996979  0.976830      0.859551  0.000100
316  0.030001  0.997105  1.104051      0.854557  0.000100
317  0.030192  0.996728  1.047661      0.855805  0.000100
318  0.028449  0.997734  1.128291      0.852684  0.000100
319  0.029931  0.997357  0.978429      0.858926  0.000100
320  0.029072  0.997860  1.314952      0.850187  0.000100
321  0.037521  0.993833  0.925078      0.855805  0.000100
322  0.035987  0.995217  1.580366      0.848315  0.000100
323  0.030110  0.996853  0.871435      0.855181  0.000100
324  0.039634  0.993329  0.787358      0.858302  0.000100
325  0.031966  0.996602  0.825595      0.866417  0.000100
326  0.030876  0.996728  0.756139      0.870786  0.000100
327  0.028190  0.997860  0.758657      0.862047  0.000100
328  0.028585  0.996728  0.722529      0.868914  0.000100
329  0.027567  0.997986  0.930571      0.859551  0.000100
330  0.026657  0.998112  0.935099      0.856429  0.000100
331  0.027710  0.997357  1.187408      0.855805  0.000100
332  0.028659  0.997105  0.936924      0.856429  0.000100
333  0.027016  0.998112  1.001042      0.860175  0.000100
334  0.025671  0.997609  1.033154      0.853308  0.000100
335  0.026927  0.997609  0.881303      0.860175  0.000100
336  0.030555  0.996224  1.031961      0.860175  0.000100
337  0.030520  0.996979  0.930343      0.852684  0.000100
338  0.026731  0.997986  1.075912      0.859551  0.000100
339  0.026597  0.997734  0.987017      0.857054  0.000100
340  0.026325  0.997860  0.939215      0.862672  0.000100
341  0.026699  0.997860  1.053815      0.854557  0.000100
342  0.026354  0.997986  0.901161      0.862047  0.000100
343  0.028620  0.996728  0.950084      0.860175  0.000100
344  0.025754  0.998112  1.087644      0.858302  0.000100
345  0.024047  0.998490  0.820930      0.866417  0.000100
346  0.027101  0.997483  1.237384      0.855181  0.000100
347  0.028429  0.997483  1.140948      0.860175  0.000100
348  0.025831  0.997734  0.989020      0.857678  0.000100
349  0.023525  0.998616  0.722128      0.863920  0.000100

[350 rows x 5 columns]

Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 192, 9)]     0                                            
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 192, 9)       36          input_1[0][0]                    
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 192, 32)      288         batch_normalization[0][0]        
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 192, 9)       0           batch_normalization[0][0]        
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 192, 64)      139264      conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 192, 64)      69632       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 192, 64)      34816       conv1d[0][0]                     
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 192, 64)      576         max_pooling1d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 192, 256)     0           conv1d_1[0][0]                   
                                                                 conv1d_2[0][0]                   
                                                                 conv1d_3[0][0]                   
                                                                 conv1d_4[0][0]                   
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 192, 256)     1024        concatenate[0][0]                
__________________________________________________________________________________________________
activation (Activation)         (None, 192, 256)     0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_5 (Conv1D)               (None, 192, 32)      8192        activation[0][0]                 
__________________________________________________________________________________________________
max_pooling1d_1 (MaxPooling1D)  (None, 192, 256)     0           activation[0][0]                 
__________________________________________________________________________________________________
conv1d_6 (Conv1D)               (None, 192, 64)      139264      conv1d_5[0][0]                   
__________________________________________________________________________________________________
conv1d_7 (Conv1D)               (None, 192, 64)      69632       conv1d_5[0][0]                   
__________________________________________________________________________________________________
conv1d_8 (Conv1D)               (None, 192, 64)      34816       conv1d_5[0][0]                   
__________________________________________________________________________________________________
conv1d_9 (Conv1D)               (None, 192, 64)      16384       max_pooling1d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 192, 256)     0           conv1d_6[0][0]                   
                                                                 conv1d_7[0][0]                   
                                                                 conv1d_8[0][0]                   
                                                                 conv1d_9[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 192, 256)     1024        concatenate_1[0][0]              
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 192, 256)     0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv1d_10 (Conv1D)              (None, 192, 32)      8192        activation_1[0][0]               
__________________________________________________________________________________________________
max_pooling1d_2 (MaxPooling1D)  (None, 192, 256)     0           activation_1[0][0]               
__________________________________________________________________________________________________
conv1d_11 (Conv1D)              (None, 192, 64)      139264      conv1d_10[0][0]                  
__________________________________________________________________________________________________
conv1d_12 (Conv1D)              (None, 192, 64)      69632       conv1d_10[0][0]                  
__________________________________________________________________________________________________
conv1d_13 (Conv1D)              (None, 192, 64)      34816       conv1d_10[0][0]                  
__________________________________________________________________________________________________
conv1d_14 (Conv1D)              (None, 192, 64)      16384       max_pooling1d_2[0][0]            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 192, 256)     0           conv1d_11[0][0]                  
                                                                 conv1d_12[0][0]                  
                                                                 conv1d_13[0][0]                  
                                                                 conv1d_14[0][0]                  
__________________________________________________________________________________________________
conv1d_15 (Conv1D)              (None, 192, 256)     2304        batch_normalization[0][0]        
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 192, 256)     1024        concatenate_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 192, 256)     1024        conv1d_15[0][0]                  
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 192, 256)     0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add (Add)                       (None, 192, 256)     0           batch_normalization_4[0][0]      
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 192, 256)     0           add[0][0]                        
__________________________________________________________________________________________________
conv1d_16 (Conv1D)              (None, 192, 32)      8192        activation_3[0][0]               
__________________________________________________________________________________________________
max_pooling1d_3 (MaxPooling1D)  (None, 192, 256)     0           activation_3[0][0]               
__________________________________________________________________________________________________
conv1d_17 (Conv1D)              (None, 192, 64)      139264      conv1d_16[0][0]                  
__________________________________________________________________________________________________
conv1d_18 (Conv1D)              (None, 192, 64)      69632       conv1d_16[0][0]                  
__________________________________________________________________________________________________
conv1d_19 (Conv1D)              (None, 192, 64)      34816       conv1d_16[0][0]                  
__________________________________________________________________________________________________
conv1d_20 (Conv1D)              (None, 192, 64)      16384       max_pooling1d_3[0][0]            
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 192, 256)     0           conv1d_17[0][0]                  
                                                                 conv1d_18[0][0]                  
                                                                 conv1d_19[0][0]                  
                                                                 conv1d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 192, 256)     1024        concatenate_3[0][0]              
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 192, 256)     0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv1d_21 (Conv1D)              (None, 192, 32)      8192        activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling1d_4 (MaxPooling1D)  (None, 192, 256)     0           activation_4[0][0]               
__________________________________________________________________________________________________
conv1d_22 (Conv1D)              (None, 192, 64)      139264      conv1d_21[0][0]                  
__________________________________________________________________________________________________
conv1d_23 (Conv1D)              (None, 192, 64)      69632       conv1d_21[0][0]                  
__________________________________________________________________________________________________
conv1d_24 (Conv1D)              (None, 192, 64)      34816       conv1d_21[0][0]                  
__________________________________________________________________________________________________
conv1d_25 (Conv1D)              (None, 192, 64)      16384       max_pooling1d_4[0][0]            
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 192, 256)     0           conv1d_22[0][0]                  
                                                                 conv1d_23[0][0]                  
                                                                 conv1d_24[0][0]                  
                                                                 conv1d_25[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 192, 256)     1024        concatenate_4[0][0]              
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 192, 256)     0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
global_average_pooling1d (Globa (None, 256)          0           activation_5[0][0]               
__________________________________________________________________________________________________
dense (Dense)                   (None, 2)            514         global_average_pooling1d[0][0]   
==================================================================================================
Total params: 1,326,726
Trainable params: 1,323,636
Non-trainable params: 3,090
__________________________________________________________________________________________________

+++Hyperparameters+++
Number of Epochs: 350
Batch Size: 64
Learning rate: 0.0005
Regularization rate: 0.00593
Network depth: 5
Filters number: 64
Max kernel size: 68
Use residual: True
Use bottleneck: True


Test Accuracy: 93.52487325668335
Test Loss: 0.32714593410491943



Classification Report
              precision    recall  f1-score   support

   No freeze       0.94      0.99      0.97      2165
      Freeze       0.63      0.23      0.34       167

    accuracy                           0.94      2332
   macro avg       0.79      0.61      0.65      2332
weighted avg       0.92      0.94      0.92      2332



Confusion Matrix
[[2142   23]
 [ 128   39]]


Normalised Confusion Matrix: True
           No freeze  Freeze
No freeze      98.94    1.06
Freeze         76.65   23.35


Finished working on: iSPLInception at: 2021-02-06 18:07:07.468228 -> 2674.905107498169

Accuracy comparison 
                       0
iSPLInception  93.524873

Loss comparison 
                      0
iSPLInception  0.327146

Accuracy comparison 
                       0
iSPLInception  93.524873

Loss comparison 
                      0
iSPLInception  0.327146

